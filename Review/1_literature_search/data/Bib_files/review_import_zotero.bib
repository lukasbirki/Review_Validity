@Article{1,
  Pages = {NA -- NA},
  Doi = {http://dx.doi.org/10.1080/21670811.2021.1943480},
  Author = {Palmer, Lindsay},
  Title = {Press Freedom during Covid-19: The Digital Discourses of the International Press Institute, Reporters Sans Frontieres, and the Committee to Protect Journalists},
  Journal = {DIGITAL JOURNALISM},
  Abstract = {This study explores the ways in which global press freedom watchdogs have discursively constructed the issue of press freedom during the Covid-19 pandemic. Drawing on a multimodal discourse analysis, the study examines web stories and Tweets posted by the International Press Institute (IPI), the Committee to Protect Journalists (CPJ), and Reporters sans Frontieres (RSF), with the purpose of answering three primary questions: (1) Who or what do the CPJ, the IPI, and RSF represent as the greatest threat to press freedom in relation to Covid-19? (2) What are the differences between these groups' representations of press freedom in their own regions of the world and their representations of press freedom in Other places? (3) What digital strategies do the IPI, CPJ, and RSF use in coverage of the Covid-19 pandemic? The article ultimately seeks to understand the ways in which each of these influential press freedom groups help to popularize particular understandings of press freedom in the 21st century.}
}


@Article{2,
  Pages = {97 -- 116},
  Doi = {http://dx.doi.org/10.1080/10584609.2017.1355857},
  Author = {Sydnor, Emily},
  Title = {Platforms for Incivility: Examining Perceptions Across Different Media Formats},
  Journal = {POLITICAL COMMUNICATION},
  Abstract = {This article investigates how the mix of attributes present across different media shapes perceptions of incivility. I argue that certain modalities, particularly the channel and structure of a media platform, facilitate the perception of media as more uncivil even if the content is kept the same. To test this argument, I conduct two survey experiments in which participants are randomly assigned to treatments in which the substantive content and text remains the same but is packaged to mimic different media types. Generally, audio and video increase awareness of incivility cues as well as participants' evaluations of negative, emotional, and entertaining tone. There are also differences in the extent to which individuals notice incivility on Twitter than on other text-based media platforms. The social media platform is also particularly entertaining in comparison to the other platforms studied. This article demonstrates that media attributes interact to shape our understanding and identification of uncivil language. Furthermore, it suggests that more attention should be focused on identifying the different sets of characteristics that make incivility more or less likely or salient in political media.},
  Volume = {35},
  Year = {2018}
}


@Article{3,
  Pages = {422 -- 441},
  Doi = {http://dx.doi.org/10.1080/21670811.2019.1682629},
  Author = {Kaiser, Jonas; Rauchfleisch, Adrian; Bourassa, Nikki},
  Title = {Connecting the (Far-)Right Dots: A Topic Modeling and Hyperlink Analysis of (Far-)Right Media Coverage during the US Elections 2016},
  Journal = {DIGITAL JOURNALISM},
  Abstract = {The 2016US election and the victory of Donald Trump are closely connected to a perceived rise of the far-right in the United States. We build upon public sphere and alternative media theory to discuss the relevance of alternative media for the US (far-)right and whether the election period and the candidate Trump allowed far-right alternative media to establish themselves in the (far-) right networked public sphere. We investigate whether it has come to a convergence of topics between the right and the extreme far-right. We analyze the topics nine right-wing outlets, ranging from Fox News to the Neo-Nazi Daily Stormer, covered in 2015/2016 during the US presidential election. We show through topic modeling of 21,919 articles how Breitbart established itself as a media outlet between the extreme far-right and mainstream right by both covering more extreme and more classic conservative topics. We show through time series clustering how Breitbart and Fox News converged in their coverage of Islam and immigration. Finally, we show through hyperlink analysis that the connection between the far-right and the mainstream right is mostly one-sided; while the alternative outlets link to more established ones, the established outlets mostly ignore the outlets from the far-right.},
  Volume = {8},
  Year = {2020}
}


@Article{4,
  Pages = {563 -- 588},
  Doi = {http://dx.doi.org/10.1093/joc/jqz033},
  Author = {Liu, Jiaying; Siegel, Leeann; Gibson, Laura A.; Kim, Yoonsang; Binns, Steven; Emery, Sherry; Hornik, Robert C.},
  Title = {Toward an Aggregate, Implicit, and Dynamic Model of Norm Formation: Capturing Large-Scale Media Representations of Dynamic Descriptive Norms Through Automated and Crowdsourced Content Analysis},
  Journal = {JOURNAL OF COMMUNICATION},
  Abstract = {Media content can shape people's descriptive norm perceptions by presenting either population-level prevalence information or descriptions of individuals' behaviors. Supervised machine learning and crowdsourcing can be combined to answer new, theoretical questions about the ways in which normative perceptions form and evolve through repeated, incidental exposure to normative mentions emanating from the media environment. Applying these methods, this study describes tobacco and e-cigarette norm prevalence and trends over 37 months through an examination of a census of 135,764 long-form media texts, 12,262 popular YouTube videos, and 75,322,911 tweets. Long-form texts mentioned tobacco population norms (4-5%) proportionately less often than e-cigarette population norms (20%). Individual use norms were common across sources, particularly YouTube (tobacco long-form: 34%; Twitter: 33%; YouTube: 88%; e-cigarette long form: 17%; Twitter: 16%; YouTube: 96%). The capacity to capture aggregated prevalence and temporal dynamics of normative media content permits asking population-level media effects questions that would otherwise be infeasible to address.},
  Volume = {69},
  Year = {2019}
}


@Article{5,
  Pages = {793 -- 813},
  Doi = {http://dx.doi.org/10.1080/10584609.2021.1901806},
  Author = {Chang, Charles},
  Title = {Information Credibility under Authoritarian Rule: Evidence from China},
  Journal = {POLITICAL COMMUNICATION},
  Abstract = {Do citizens under authoritarian rule trust government information? To answer this question, I compared citizen statements and movement trajectories from smartphone social media communication in real-time with precise timestamps and locations in response to the government's press releases during the Kunming railway station attack in southwestern China in 2014. I find that while outward engagement with government information may increase as the government releases more information, citizen trust in such information, in fact, diminishes, even when the information itself is straightforward and factual. In other words, an authoritarian government's efforts to disseminate information comes with a cost - its credibility.},
  Volume = {38},
  Year = {2021}
}


@Article{6,
  Pages = {345 -- 372},
  Doi = {http://dx.doi.org/10.1093/joc/jqz023},
  Author = {Jaidka, Kokil; Zhou, Alvin; Lelkes, Yphtach},
  Title = {Brevity is the Soul of Twitter: The Constraint Affordance and Political Discussion},
  Journal = {JOURNAL OF COMMUNICATION},
  Abstract = {Many hoped that social networking sites would allow for the open exchange of information and a revival of the public sphere. Unfortunately, conversations on social media are often toxic and not conducive to healthy political discussions. Twitter, the most widely used social network for political discussions, doubled the limit of characters in a tweet in November 2017, which provided an opportunity to study the effect of technological affordances on political discussions using a discontinuous time series design. Using supervised and unsupervised natural language processing methods, we analyzed 358,242 tweet replies to U.S. politicians from January 2017 to March 2018. We show that doubling the permissible length of a tweet led to less uncivil, more polite, and more constructive discussions online. However, the declining trend in the empathy and respectfulness of these tweets raises concerns about the implications of the changing norms for the quality of political deliberation.},
  Volume = {69},
  Year = {2019}
}


@Article{7,
  Pages = {851 -- 873},
  Doi = {http://dx.doi.org/10.1111/jcom.12335},
  Author = {Coe, Kevin; Bruce, Robert J.; Ratcliff, Chelsea L.},
  Title = {Presidential Communication About Marginalized Groups: Applying a New Analytic Framework in the Context of the LGBT Community},
  Journal = {JOURNAL OF COMMUNICATION},
  Abstract = {Scholars have long observed that presidential communication about a marginalized group can help shape that group's reality. Yet most analyses of such communication focus on a relatively small number of texts, making it difficult to identify important changes over time and analyze factors that might explain those changes. The present study proposes an analytic framework that specifies 4 measurable parameters of presidential communication about marginalized groups, as well as 4 explanatory factors. We use this framework to analyze the census of presidents' formal communications about the LGBT community. Results highlight presidents' limited communicative engagement with the LGBT community and the roles that political party, rhetorical context, public opinion, and sociocultural touchstones play in explaining presidential communication about this important group.},
  Volume = {67},
  Year = {2017}
}


@Article{8,
  Pages = {165 -- 183},
  Doi = {http://dx.doi.org/10.1080/19312458.2020.1803247},
  Author = {Baden, Christian; Kligler-Vilenchik, Neta; Yarchi, Moran},
  Title = {Hybrid Content Analysis: Toward a Strategy for the Theory-driven, Computer-assisted Classification of Large Text Corpora},
  Journal = {COMMUNICATION METHODS AND MEASURES},
  Abstract = {Given the scale of digital communication, researchers face a painful trade-off between powerful, scalable computational strategies, and the theoretical sensitivity offered by small-scale manual analyses. Especially in the study of natural discourse on digital media, the interactive, ever-evolving stream of conversations across multiple platforms regularly defies efforts to obtain well-defined samples of manageable size, while their linguistic variability imposes major limitations upon the accuracy of automated tools. In this paper, we draw upon recent advances in computational text analysis to develop a hybrid approach to the deductive analysis of large-scale digital discourse, which combines the algorithmic extraction of coherent, recurrent patterns with a manual coding of identified patterns. The approach scales up to treat millions of texts at minimal added human effort, while affording researchers close control over the process of theory-guided classification. We demonstrate the power of Hybrid Content Analysis by studying polarization in a quarter of a million contributions from cross-platform interactive social media discourse about a controversial incident.},
  Volume = {14},
  Year = {2020}
}


@Article{9,
  Pages = {266 -- 284},
  Doi = {http://dx.doi.org/10.1080/19312458.2020.1825659},
  Author = {Amsalem, Eran; Fogel-Dror, Yair; Shenhav, Shaul R.; Sheafer, Tamir},
  Title = {Fine-Grained Analysis of Diversity Levels in the News},
  Journal = {COMMUNICATION METHODS AND MEASURES},
  Abstract = {Many researchers consider the presentation of diverse content as a prerequisite for the news media to fully exercise their democratic mandate. While prior news diversity studies have contributed important theoretical insights, we argue here that scholarly knowledge of this concept can be significantly advanced by employing computational methods for text analysis. Using automated methods, researchers can increase both the scope of data being analyzed and the resolution of the analysis. This article presents a novel framework for analyzing news diversity consisting of two distinct stages. In the first stage, a computational text classification method is used to analyze, at a high resolution, the attention given in news texts to a broad range of political and social issues. In the second stage, the text classifications are aggregated, and the distributions of media attention to those issues (i.e., news diversity) are assessed on a large scale. After presenting the novel approach, we illustrate its usefulness for testing theoretical hypotheses about news diversity. We compare the diversity of economic coverage in three elite and three popular US newspapers (N= 252,807 articles) and find that a fine-grained analysis relaxes concerns raised in previous studies about low content diversity in the popular press.},
  Volume = {14},
  Year = {2020}
}


@Article{10,
  Pages = {NA -- NA}
}


@Article{11,
  Pages = {47 -- 64},
  Doi = {http://dx.doi.org/10.1017/pan.2019.18},
  Author = {Bustikova, Lenka; Siroky, David S.; Alashri, Saud; Alzahrani, Sultan},
  Title = {Predicting Partisan Responsiveness: A Probabilistic Text Mining Time-Series Approach},
  Journal = {POLITICAL ANALYSIS},
  Abstract = {When do parties respond to their political rivals and when do they ignore them? This article presents a new computational framework to detect, analyze and predict partisan responsiveness by showing when parties on opposite poles of the political spectrum react to each other's agendas and thereby contribute to polarization. Once spikes in responsiveness are detected and categorized using latent Dirichlet allocation, we utilize the terms that comprise the topics, together with a gradient descent solver, to assess the classifier's predictive accuracy. Using 10,597 documents from the official websites of radical right and ethnic political parties in Slovakia (2004-2014), the analysis predicts which political issues will elicit partisan reactions, and which will be ignored, with an accuracy of 83% (F-measure) and outperforms both Random Forest and Naive Bayes classifiers. Subject matter experts validate the approach and interpret the results.},
  Volume = {28},
  Year = {2020}
}


@Article{12,
  Pages = {122 -- 145},
  Doi = {http://dx.doi.org/10.1080/10584609.2021.1960451},
  Author = {Ji, Chengyuan; Liu, Hanzhang},
  Title = {State as Salesman: International Economic Engagement and Foreign News Coverage in China},
  Journal = {POLITICAL COMMUNICATION},
  Abstract = {How does an authoritarian regime cover news about foreign countries for its domestic audience? What accounts for the variation in news coverage received by different foreign countries? While existing literature points to political concerns at home, in this article, we argue that a regime's economic interests can also be a driving force: the desire to deepen its international economic engagement can motivate the regime to treat foreign countries differently in its news coverage. To test this argument, we examine foreign news coverage by China's state-run television network between 2003 and 2018. Combining textual and quantitative analysis, we find that countries with stronger economic ties with China receive more favorable news coverage. Moreover, the manipulation of coverage favorability is achieved through selective reporting: negative events such as armed conflicts receive less coverage when taking place in a country with close economic ties with China. These findings contribute to our understanding of international news flow, especially in a non-Western setting. They also demonstrate a pragmatic rather than political use of information control by an authoritarian government.},
  Volume = {39},
  Year = {2022}
}


@Article{13,
  Pages = {80 -- 99},
  Doi = {http://dx.doi.org/10.1080/21670811.2017.1399805},
  Author = {Russell, Frank Michael},
  Title = {TWITTER AND NEWS GATEKEEPING Interactivity, reciprocity, and promotion in news organizations' tweets},
  Journal = {DIGITAL JOURNALISM},
  Abstract = {This study concerns Twitter use by 26 news entities with the largest online audiences in the United States. A quantitative content analysis compared interactive characteristics of posts on news organizations' main Twitter accounts. Most of the tweets included hyperlinks to articles posted on the news organizations' websites along with text about the articles and a photograph or other still image. Differences existed between news organizations in the use of such hyperlinks to their own websites, as well as socially and technically interactive functions of Twitter such as retweets, @mentions, hash tags, and multimedia. Tweets with interactive characteristics seemed intended mainly for the purpose of promoting news organizations' programming or content.},
  Volume = {7},
  Year = {2019}
}


@Article{14,
  Pages = {594 -- 624},
  Doi = {http://dx.doi.org/10.1080/10584609.2014.986349},
  Author = {Benkler, Yochai; Roberts, Hal; Faris, Robert; Solow-Niederman, Alicia; Etling, Bruce},
  Title = {Social Mobilization and the Networked Public Sphere: Mapping the SOPA-PIPA Debate},
  Journal = {POLITICAL COMMUNICATION},
  Abstract = {This article investigates the public debate over proposed U.S. legislation designed to give prosecutors and copyright holders new tools to pursue suspected online copyright violations. We compiled, mapped, and analyzed a set of 9,757 stories published over 16 months relevant to the Combating Online Infringement and Counterfeits Act (COICA), Stop Online Piracy Act (SOPA), and PROTECT IP Act (PIPA). This study applies a mixed-methods approach that combines text and link analysis with human coding and informal interviews to map the evolution of the controversy over time and to analyze the mobilization, roles, and interactions of various actors. We find a vibrant, diverse, and decentralized networked public sphere that exhibited broad participation, leveraged topical expertise, and successfully reframed a debate and focused public sentiment to shape national public policy. A network of small-scale commercial tech media, nongovernmental organizations (NGOs), and individuals fulfilled the fourth estate function; traditional media then amplified the work of these actors. The campaign involved substantial experimentation and rapid development of mobilization strategies. We observe an increased public awareness of an agenda originating in the networked public sphere, which emerged successfully despite substantial expenditures attempting to produce a mass media narrative that favored the legislation. Moreover, we witness what we call an attention backbone, in which more trafficked sites amplify less-visible individual voices on specific subjects. The data suggest that, at least in this case, the networked public sphere enabled a dynamic public discourse that involved both individual and organizational participants and offered substantive discussion of complex issues contributing to affirmative political action.},
  Volume = {32},
  Year = {2015}
}


@Article{15,
  Pages = {159 -- 181},
  Doi = {http://dx.doi.org/10.1080/10584609.2020.1812777},
  Author = {Nicholls, Tom; Culpepper, Pepper D.},
  Title = {Computational Identification of Media Frames: Strengths, Weaknesses, and Opportunities},
  Journal = {POLITICAL COMMUNICATION},
  Abstract = {With the availability of large volumes of electronic communications data and the increasing sophistication of computational techniques, the development of automated approaches for different kinds of framing analysis is an important goal of researchers. There is as yet no standard method for the unsupervised inductive identification of frames based upon the content of articles. Three groups of core approaches underlie a wide range of work in this area, and we compare three techniques based on these approaches against each other and against manual human analysts. The three techniques are a k-means clustering algorithm together with a sophisticated natural language processing (NLP)-based feature selection process; evolutionary factor analysis (EFA), a factor analysis approach; and the structural topic model (STM). We use two datasets - one very focused and one extremely broad - as examples of the kind of frame analysis problems readers may wish to attempt. Even in a highly targeted dataset, we find some distance between the frames generated by computational analysis and those manually produced by our human analysts. The details of each method have a substantial impact on frame quality and interpretation. We find that the STM approach is the most effective for our narrow-scope dataset, but that it returns definite topics, and not frames, when working on our very broad dataset. We also show that we can get results emphasizing different parts of the framing problem by combining parts of different methods as a multi-stage process, rather than viewing available methods as simple plug-and-play models.},
  Volume = {38},
  Year = {2021}
}


@Article{16,
  Pages = {45 -- 62},
  Doi = {http://dx.doi.org/10.1080/21670811.2018.1493939},
  Author = {Welbers, Kasper; Opgenhaffen, Michael},
  Title = {PRESENTING NEWS ON SOCIAL MEDIA Media logic in the communication style of newspapers on Facebook},
  Journal = {DIGITAL JOURNALISM},
  Abstract = {With the rising popularity of social media as news sources, a new common format element for presenting news has emerged: in addition to the classic headline, lead and picture, news organizations add a status message when they share their news articles on social media such as Twitter and Facebook. Based on media logic theory, we argue that the communication style of these messages is likely to be more interpersonal and subjective. To investigate this we used computational text analysis to compare status messages to headlines and leads, covering nine newspapers from the Netherlands and Flanders over a period of 2.5 years. We conclude that newspapers use status messages to add a subjective expression to news on social media, and call for research into how this takes shape and affects the audience.},
  Volume = {7},
  Year = {2019}
}


@Article{17,
  Pages = {NA -- NA},
  Doi = {http://dx.doi.org/10.1080/19312458.2021.1999913},
  Author = {Dobbrick, Timo; Jakob, Julia; Chan, Chung-Hong; Wessler, Hartmut},
  Title = {Enhancing Theory-Informed Dictionary Approaches with Glass-box Machine Learning: The Case of Integrative Complexity in Social Media Comments},
  Journal = {COMMUNICATION METHODS AND MEASURES},
  Abstract = {Dictionary-based approaches to computational text analysis have been shown to perform relatively poorly, particularly when the dictionaries rely on simple bags of words, are not specified for the domain under study, and add word scores without weighting. While machine learning approaches usually perform better, they offer little insight into (a) which of the assumptions underlying dictionary approaches (bag-of-words, domain transferability, or additivity) impedes performance most, and (b) which language features drive the algorithmic classification most strongly. To fill both gaps, we offer a systematic assumption-based error analysis, using the integrative complexity of social media comments as our case in point. We show that attacking the additivity assumption offers the strongest potential for improving dictionary performance. We also propose to combine off-the-shelf dictionaries with supervised glass box machine learning algorithms (as opposed to the usual black box machine learning approaches) to classify texts and learn about the most important features for classification. This dictionary-plus-supervised-learning approach performs similarly well as classic full-text machine learning or deep learning approaches, but yields interpretable results in addition, which can inform theory development on top of enabling a valid classification.}
}


@Article{18,
  Pages = {109 -- 125},
  Doi = {http://dx.doi.org/10.1017/S0003055419000650},
  Author = {Pan, Jennifer; Siegel, Alexandra A.},
  Title = {How Saudi Crackdowns Fail to Silence Online Dissent},
  Journal = {AMERICAN POLITICAL SCIENCE REVIEW},
  Abstract = {Saudi Arabia has imprisoned and tortured activists, religious leaders, and journalists for voicing dissent online. This reflects a growing worldwide trend in the use of physical repression to censor online speech. In this paper, we systematically examine the consequences of imprisoning well-known Saudis for online dissent by analyzing over 300 million tweets as well as detailed Google search data from 2010 to 2017 using automated text analysis and crowd-sourced human evaluation of content. We find that repression deterred imprisoned Saudis from continuing to dissent online. However, it did not suppress dissent overall. Twitter followers of the imprisoned Saudis engaged in more online dissent, including criticizing the ruling family and calling for regime change. Repression drew public attention to arrested Saudis and their causes, and other prominent figures in Saudi Arabia were not deterred by the repression of their peers and continued to dissent online.},
  Volume = {114},
  Year = {2020}
}


@Article{19,
  Pages = {140 -- 157},
  Doi = {http://dx.doi.org/10.1080/19312458.2018.1455817},
  Author = {Rudkowsky, Elena; Haselmayer, Martin; Wastian, Matthias; Jenny, Marcelo; Emrich, Stefan; Sedlmair, Michael},
  Title = {More than Bags of Words: Sentiment Analysis with Word Embeddings},
  Journal = {COMMUNICATION METHODS AND MEASURES},
  Abstract = {Moving beyond the dominant bag-of-words approach to sentiment analysis we introduce an alternative procedure based on distributed word embeddings. The strength of word embeddings is the ability to capture similarities in word meaning. We use word embeddings as part of a supervised machine learning procedure which estimates levels of negativity in parliamentary speeches. The procedure's accuracy is evaluated with crowdcoded training sentences; its external validity through a study of patterns of negativity in Austrian parliamentary speeches. The results show the potential of the word embeddings approach for sentiment analysis in the social sciences.},
  Volume = {12},
  Year = {2018}
}


@Article{20,
  Pages = {191 -- 209},
  Doi = {http://dx.doi.org/10.1080/19312458.2017.1317338},
  Author = {Lind, Fabienne; Gruber, Maria; Boomgaarden, Hajo G.},
  Title = {Content Analysis by the Crowd: Assessing the Usability of Crowdsourcing for Coding Latent Constructs},
  Journal = {COMMUNICATION METHODS AND MEASURES},
  Abstract = {Crowdsourcing platforms are commonly used for research in the humanities, social sciences and informatics, including the use of crowdworkers to annotate textual material or visuals. Utilizing two empirical studies, this article systematically assesses the potential of crowdcoding for lessmanifest contents of news texts, here focusing on political actor evaluations. Specifically, Study 1 compares the reliability and validity of crowdcoded data to that of manual content analyses; Study 2 proceeds to investigate the effects of material presentation, different types of coding instructions and answer option formats on data quality. We find that the performance of the crowd recommends crowdcoded data as a reliable and valid alternative to manually coded data, also for less manifest contents. While scale manipulations affected the results, minor modifications of the coding instructions or material presentation did not significantly influence data quality. In sum, crowdcoding appears a robust instrument to collect quantitative content data.},
  Volume = {11},
  Year = {2017}
}
